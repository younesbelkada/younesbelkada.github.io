<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Deep Learning - Tag - Younes Belkada's blog</title><link>http://example.org/tags/deep-learning/</link><description>Deep Learning - Tag - Younes Belkada's blog</description><generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>younesbelkada@gmail.com (Younes Belkada)</managingEditor><webMaster>younesbelkada@gmail.com (Younes Belkada)</webMaster><lastBuildDate>Sat, 12 Mar 2022 00:00:00 +0000</lastBuildDate><atom:link href="http://example.org/tags/deep-learning/" rel="self" type="application/rss+xml"/><item><title>InterfaceGAN++: How far can we go with InterfaceGAN?</title><link>http://example.org/posts/interface-gan/</link><pubDate>Sat, 12 Mar 2022 00:00:00 +0000</pubDate><author>younesbelkada@gmail.com (Younes Belkada)</author><guid>http://example.org/posts/interface-gan/</guid><description>&lt;div class="featured-image">
&lt;img src="/images/posts/interfacegan.gif" referrerpolicy="no-referrer">
&lt;/div>I would like to explain in this post, one the projects I was involved during my Masters degree at ENS Paris Saclay, during the Introduction to Numerical Imaging course.
Introduction InterfaceGAN is a paper that has been published on CVPR 2020, by Yujin Shen et al. It argues that well-trained generative models learns a disentangled latent space representation.
Basically given a generated face image from a random gaussian noise, InterfaceGAN can control some specific attributes of the face without altering the semantic information of it.</description></item><item><title>Mastering Natural Language Processing - Words as vectors</title><link>http://example.org/posts/nlp-1/</link><pubDate>Sun, 16 Jan 2022 00:00:00 +0000</pubDate><author>younesbelkada@gmail.com (Younes Belkada)</author><guid>http://example.org/posts/nlp-1/</guid><description>&lt;div class="featured-image">
&lt;img src="/images/posts/nlp_1.png" referrerpolicy="no-referrer">
&lt;/div>Why NLP is so exciting? Natural Language Processing is an application of AI and Deep Learning that allows machines and algorithms understand languages (Natural Language) in order to easily deal with any problems related to text (text classification, sentiment analysis, summarization, etc.). There is also a very large interest around NLP from big tech companies and investors as the potential applications of Deep Learning for NLP are becoming more and more impactful.</description></item><item><title>'Do pedestrians pay attention? Eye contact detection in the wild' on arxiv</title><link>http://example.org/posts/looking/</link><pubDate>Thu, 23 Dec 2021 00:00:00 +0000</pubDate><author>younesbelkada@gmail.com (Younes Belkada)</author><guid>http://example.org/posts/looking/</guid><description><![CDATA[<div class="featured-image">
                <img src="/images/projects/looking.png" referrerpolicy="no-referrer">
            </div>The paper &lsquo;Do pedestrians pay attention? Eye contact detection in the wild&rsquo; is finally on arxiv after its submission to the Intelligent Transportation Journal (ITS). You can find the paper, its implementation as well as the released benchmark on this website]]></description></item><item><title>Imitation Learning explained</title><link>http://example.org/posts/imitation_learning/</link><pubDate>Thu, 14 Oct 2021 00:00:00 +0000</pubDate><author>younesbelkada@gmail.com (Younes Belkada)</author><guid>http://example.org/posts/imitation_learning/</guid><description><![CDATA[<div class="featured-image">
                <img src="/images/posts/robot-reading.png" referrerpolicy="no-referrer">
            </div>Here is my attempt to explain the notions and intuitions behind Imitation Learning with the best of my knowledge. Credits to this very nice blog where I have learned most of the things that I have understood about the concept, and to this website for the image above. Now let&rsquo;s directly dive in.
1. Brief intuitions In Reinforcement Learning, you learn to make good sequence of decisionsSource: http://web.stanford.edu/class/cs234/slides/lecture1.pdf
" In Reinforcement Learning, you learn to make good sequence of decisions  The field of Reinforcement Learning is an area of machine learning where an intelligent agent interacts with an environment in order to learn a policy (i.]]></description></item><item><title>Challenge 1 - Brain Tumor classification on Kaggle</title><link>http://example.org/posts/brain_tumor/</link><pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate><author>younesbelkada@gmail.com (Younes Belkada)</author><guid>http://example.org/posts/brain_tumor/</guid><description><![CDATA[<div class="featured-image">
                <img src="/images/projects/brain.png" referrerpolicy="no-referrer">
            </div>We decided with my friend Arthur Zucker to challenge ourselves into this Kaggle competition. The project looks quite exciting, with a serious and challenging application on a real-wolrd problem. According to the official Kaggle repository: A malignant tumor in the brain is a life-threatening condition. Known as glioblastoma, it&rsquo;s both the most common form of brain cancer in adults and the one with the worst prognosis, with median survival being less than a year.]]></description></item><item><title>A frist approach for steganography using Language Models</title><link>http://example.org/projects/stego-ml/</link><pubDate>Thu, 24 Dec 2020 00:00:00 +0000</pubDate><author>younesbelkada@gmail.com (Younes Belkada)</author><guid>http://example.org/projects/stego-ml/</guid><description>Introduction This project was conducted upon the EPFL CS-433 course, for a semester project, during the fall semester 2020. This project tries to find a novel approach for steganography applied to text data using Language Models.
What is Steganography ? The principle of Steganography is to hide a secret message inside another message or in an image. These techniques can be used to avoid Man In the Middle (MITM) attacks and send secret messages to a pre-defined receiver.</description></item><item><title>In-the-wild eye contact detection for Autonomous Vehicles</title><link>http://example.org/projects/looking/</link><pubDate>Sun, 25 Jul 2021 00:00:00 +0000</pubDate><author>younesbelkada@gmail.com (Younes Belkada)</author><guid>http://example.org/projects/looking/</guid><description>The method performs in-the-wild eye contact detection" The method performs in-the-wild eye contact detection Problem statement The task of in-the-wild eye contact detection for autonomous agents is under-estimated in the Deep Learning literature today. To the best of our knowledge, there are very few studies about this task and there is a lack of labeled dataset for the latest. Eye-contact detection in the context of autonomous driving is extremely challenging and useful.</description></item><item><title>An approach for fitness exercise scoring using Deep Learning</title><link>http://example.org/projects/pose-socring/</link><pubDate>Sun, 24 May 2020 20:26:19 +0200</pubDate><author>younesbelkada@gmail.com (Younes Belkada)</author><guid>http://example.org/projects/pose-socring/</guid><description>Introduction Imagine a world where (almost) everything is powered by Artificial Intelligence. Today, some signs of an Artifical Intelligence-guided society are coming into existence. Autonomous cars can automately drive you from a point A to a point B, and more recently, Tesla has revealed the Tesla Bot, the humanoid robot that will be able to help humans for simple tasks.
Elon Musk when revealing the Tesla Bot - August 2021 -Source: autoplus.</description></item></channel></rss>