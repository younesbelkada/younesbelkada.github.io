<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="chrome=1"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><link rel=canonical href=https://younesbelkada.github.io/2021/brain-tumor/><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#da532c"><meta name=theme-color content="#ffffff"><title>Challenge '#1 Brain Tumor classification on Kaggle | Younes Belkada</title><meta name=title content="Challenge '#1 Brain Tumor classification on Kaggle | Younes Belkada"><link rel=stylesheet href=/font/iconfont.css><link rel=stylesheet href=/css/main.min.css><meta name=twitter:card content="summary"><meta name=twitter:title content="Challenge '#1 Brain Tumor classification on Kaggle"><meta name=twitter:description content="We decided with my friend Arthur Zucker to challenge ourselves into this Kaggle competition. The project looks quite exciting, with a serious and challenging application on a real-wolrd problem. According to the official Kaggle repository: A malignant tumor in the brain is a life-threatening condition. Known as glioblastoma, it&rsquo;s both the most common form of brain cancer in adults and the one with the worst prognosis, with median survival being less than a year."><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Challenge \u0027#1 Brain Tumor classification on Kaggle","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/younesbelkada.github.io\/2021\/brain-tumor\/"},"image":{"@type":"ImageObject","url":"https:\/\/younesbelkada.github.io\/cover.png","width":800,"height":600},"genre":"posts","wordcount":760,"url":"https:\/\/younesbelkada.github.io\/2021\/brain-tumor\/","datePublished":"2021-07-27T00:00:00\u002b00:00","dateModified":"2021-07-27T00:00:00\u002b00:00","publisher":{"@type":"Organization","name":"Fastbyte01","logo":{"@type":"ImageObject","url":"https:\/\/younesbelkada.github.io\/logo.png","width":127,"height":40}},"author":{"@type":"Person","name":"Younes Belkada"},"description":""}</script></head><body><div class=wrapper><nav class=navbar><div class=container><div class="navbar-header header-logo"><a href=https://younesbelkada.github.io/>Younes Belkada</a></div><div class="menu navbar-right"><a class=menu-item href=/posts/ title>Blog</a>
<a class=menu-item href=/categories/ title>Categories</a>
<a class=menu-item href=/projects/ title>Projects</a>
<a class=menu-item href=/about title>About</a>
<a href=javascript:void(0); class=theme-switch><i class="iconfont icon-sun"></i></a>&nbsp;</div></div></nav><nav class=navbar-mobile id=nav-mobile style=display:none><div class=container><div class=navbar-header><div><a href=javascript:void(0); class=theme-switch><i class="iconfont icon-sun"></i></a>&nbsp;<a href=https://younesbelkada.github.io/>Younes Belkada</a></div><div class=menu-toggle><span></span><span></span><span></span></div></div><div class=menu id=mobile-menu><a class=menu-item href=/posts/ title>Blog</a>
<a class=menu-item href=/categories/ title>Categories</a>
<a class=menu-item href=/projects/ title>Projects</a>
<a class=menu-item href=/about title>About</a></div></div></nav><main class=main><div class=container><article class=post-warp><header class=post-header><h1 class=post-title>Challenge '#1 Brain Tumor classification on Kaggle</h1><div class=post-meta>Written by <a href=https://younesbelkada.github.io/ rel=author>Younes Belkada</a> with ♥
<span class=post-time>on <time datetime=2021-07-27>27 July 2021</time></span>
in
<i class="iconfont icon-folder"></i>
<span class=post-category><a href=https://younesbelkada.github.io/categories/challenges/>Challenges</a></span>
<i class="iconfont icon-timer"></i>
4 min</div></header><div class=post-content><p><figure><img src=/images/ring.svg data-sizes=auto data-src=/images/projects/brain.png alt="Source of the image: https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification/overview" class=lazyload><figcaption class=image-caption>Source of the image: https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification/overview</figcaption></figure></p><p>We decided with my friend <a href=https://arthurzucker.github.io/>Arthur Zucker</a> to challenge ourselves into this <a href=https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification/overview>Kaggle competition</a>.
The project looks quite exciting, with a serious and challenging application on a real-wolrd problem. According to the official Kaggle repository: <em>A malignant tumor in the brain is a life-threatening condition. Known as glioblastoma, it&rsquo;s both the most common form of brain cancer in adults and the one with the worst prognosis, with median survival being less than a year. The presence of a specific genetic sequence in the tumor known as MGMT promoter methylation has been shown to be a favorable prognostic factor and a strong predictor of responsiveness to chemotherapy</em>.</p><h1 id=project-overview>Project overview</h1><p>The goal is to accurately predict if the patient is victim of a malignant tumor, given a set of different scan of the brain scan taken with 4 different image types called structural multi-parametric MRI (mpMRI) scans. The problem can be tackled in several ways that we will try to explore as much as we can !</p><h3 id=the-dataset>The dataset</h3><p>For any type of Data Science / Machine Learning problem, understanding the dataset is the <em><strong>most crucial</strong></em> part. To the best of our knowledge, the dataset consists with a set of labeled ~1000 patients data. As explained above, each patient has a different type of scan images. The image files are stored in the DICOM format. A good explanation of how to understand the DICOM files can be found <a href=https://www.researchgate.net/post/Deep_Learning_What_is_the_best_way_to_to_feed_dicom_files_into_object_detection_algorithm>here</a>. I will try to give a brief explanation of what is a DICOM file.</p><h4 id=what-is-a-dicom-file>What is a DICOM file?</h4><p><a href=https://www.dicomstandard.org/>DICOM</a> is the international standard for medical images and related information, it is the best way for medical staff to display fine-grained information about the examined region. Each pixel intensity corresponds to a particular zone of the organ.</p><p>Classic images are stored in an array with values from range 0-255. Depending on the tool that is used to get the scan, the pixel arrays of the DICOM images are stored in a 0-4000 range.</p><p>This fact complexifies the problem since classic Deep Learning models for computer vision are trained on classic images, by normalizing the DICOM images we may lose some critical information contained in the scan.. <em><strong>or not.</strong></em> Hopefully the models will learn how to handle these images.</p><p><figure><img src=/images/ring.svg data-sizes=auto data-src=/images/projects/scan_dicom.png alt="Example of a DICOM scan. Each pixel intensity is mapped to a particular region of the organ (skin, bone, etc.)" class=lazyload><figcaption class=image-caption>Example of a DICOM scan. Each pixel intensity is mapped to a particular region of the organ (skin, bone, etc.)</figcaption></figure></p><h4 id=patient-data-as-a-video>Patient data as a video</h4><p>To understand better the dataset, let&rsquo;s get a closer look at the structure of the data:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>Training/Validation/Testing
│
└─── <span style=color:#ae81ff>00000</span>
│   │
│   └─── FLAIR
│   │   │ Image-1.dcm
│   │   │ Image-2.dcm
│   │   │ ...
│   │   
│   └─── T1w
│   │   │ Image-1.dcm
│   │   │ Image-2.dcm
│   │   │ ...
│   │   
│   └─── T1wCE
│   │   │ Image-1.dcm
│   │   │ Image-2.dcm
│   │   │ ...
│   │   
│   └─── T2w
│   │   │ Image-1.dcm
│   │   │ Image-2.dcm
│   │   │ .....
│   
└─── <span style=color:#ae81ff>00001</span>
│   │ ...
│   
│ ...   
│   
└─── <span style=color:#ae81ff>00002</span>
│   │ ...                 
</code></pre></div><p>Each patient, identified by its unique 5-digits id, contains 4 sub-folders corresponding to the scan type. The length of each folder has an arbitrary number of images, for e.g. the folder <code>00000/FLAIR</code> can have 400 images whereas the folder <code>00010/FLAIR</code> can have 325 images. Note also that the content of each folder is the frames of the video scan of the brain of the patient.</p><p><figure><img src=/images/ring.svg data-sizes=auto data-src=/images/projects/brain.gif alt="Qualitative example of the frames that can be contained inside each sub-folder - source: https://theaisummer.com/medical-image-coordinates/" class=lazyload><figcaption class=image-caption>Qualitative example of the frames that can be contained inside each sub-folder - source: https://theaisummer.com/medical-image-coordinates/</figcaption></figure></p><h3 id=the-main-goal>The main goal</h3><p>The main goal can be summarized as follows: perform binary classification given a set of images.</p><p>The goal is a bit tricky. <em><strong>Why?</strong></em></p><p>Because classicaly, when performing binary classification the input is a single image (e.g. Dogs and Cat classification), in this case the input would be a set of <em><strong>arbitrary number of images</strong></em>, and the output is whether the tumor is present in the scans or not.</p><h4 id=the-challenges>The challenges</h4><p>As stated before, for me the main challenge is to understand how to train a model that deals with this additional constraint of the different number of frames per subfolder. Different directions can be discussed:</p><ul><li>Use the mean image per subfolder and pass it to a <em>ResNet</em> or an <em>EfficientNet</em></li><li>Take a random image and pass it to the model</li><li>Transform each image to another space and pass it to a Sequential model (RNN, LSTM)</li><li>Transform each image into a 4d tensor and make use of 3d convolutional models</li></ul><p>Intuitively I would go for the third option. The risk of losing crucial information is extremely high if we decide to go for the first 2 directions. We may use these 2 options as a baseline and compare it against the approach 3.</p><h1 id=our-implementation>Our implementation</h1><p>To be released soon !</p></div><div class=post-copyright><p class=copyright-item><span>Author:</span>
<span>younesbelkada</span></p><p class=copyright-item><span>Words:</span>
<span>760</span></p><p class=copyright-item><span>Share:</span>
<span><a href="//twitter.com/share?url=https%3a%2f%2fyounesbelkada.github.io%2f2021%2fbrain-tumor%2f&text=Challenge%20%27%231%20Brain%20Tumor%20classification%20on%20Kaggle&via=" target=_blank title="Share on Twitter"><i class="iconfont icon-twitter"></i></a>
<a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fyounesbelkada.github.io%2f2021%2fbrain-tumor%2f" target=_blank title="Share on Facebook"><i class="iconfont icon-facebook"></i></a>
<a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2fyounesbelkada.github.io%2f2021%2fbrain-tumor%2f&title=Challenge%20%27%231%20Brain%20Tumor%20classification%20on%20Kaggle" target=_blank title="Share on LinkedIn"><i class="iconfont icon-linkedin"></i></a></span></p><p class=copyright-item>Released under <a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></p></div><div class=post-tags><section><a href=javascript:window.history.back();>Back</a></span> ·
<span><a href=https://younesbelkada.github.io/>Home</a></span></section></div><div class=post-nav></div><div class=post-comment><div id=disqus_thread></div><script type=text/javascript>(function(){var a,b;if(window.location.hostname=="localhost")return;a=document.createElement('script'),a.type='text/javascript',a.async=!0,b='yourdiscussshortname',a.src='//'+b+'.disqus.com/embed.js',(document.getElementsByTagName('head')[0]||document.getElementsByTagName('body')[0]).appendChild(a)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com/ class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></article></div></main><footer class=footer><div class=copyright>&copy;
<span itemprop=copyrightYear>2021 - 2021</span>
<span class=author itemprop=copyrightHolder><a href=https://younesbelkada.github.io/>younesbelkada</a> |</span>
<span>Crafted with ❤️ by <a href=https://github.com/Fastbyte01/KeepIt target=_blank rel="external nofollow noopener noreffer">KeepIt</a> & <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreffer">Hugo</a></span></div></footer><link crossorigin=anonymous integrity=sha384-yziQACfvCVwLqVFLqkWBYRO3XeA4EqzfXKGwaWnenYn5XzqfJFlFdKEmvutIQdKb href=https://lib.baomitu.com/lightgallery/1.10.0/css/lightgallery.min.css rel=stylesheet><script src=/js/vendor_gallery.min.js async></script></div></body></html>