<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Course notes on Younes Belkada</title><link>https://younesbelkada.github.io/categories/course-notes/</link><description>Recent content in Course notes on Younes Belkada</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Tue, 12 Oct 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://younesbelkada.github.io/categories/course-notes/index.xml" rel="self" type="application/rss+xml"/><item><title>Week 2 - RL Course</title><link>https://younesbelkada.github.io/notes/rl2/</link><pubDate>Tue, 12 Oct 2021 00:00:00 +0000</pubDate><guid>https://younesbelkada.github.io/notes/rl2/</guid><description>In the previous section we have seen how to formulate a RL problem using MDPs and provide some tips in order to analytically evaluate a policy (set of actions at each set) if some variables were known beforehand using the Bellman equation and the Bellman operator.
Here in the second lecture we are going to tackle the issue of how to solve an MDP (i.e get the optimal policy $\pi$) given some parameters of the problem.</description></item><item><title>Week 1 - RL Course</title><link>https://younesbelkada.github.io/notes/rl1/</link><pubDate>Tue, 05 Oct 2021 00:00:00 +0000</pubDate><guid>https://younesbelkada.github.io/notes/rl1/</guid><description>Here is the first personal notes from the Reinforcement Learning course that I have decided to take at the MVA Master&amp;rsquo;s program. The course is quite theoretical and this is challenging for me since I have (almost) zero knowledge on Reinforcement Learning. I have decided to try to explain what I have understood in each lecture in order to assimilate the content of each session.
What is Reinforcement Learning? RL is a family of Machine Learning techniques in order to solve a task that is based on the current and previous states of an agent interacting with an environement.</description></item></channel></rss>