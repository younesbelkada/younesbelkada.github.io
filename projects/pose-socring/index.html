<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>An approach for fitness exercise scoring using Deep Learning - Younes Belkada's blog</title><meta name=description content="Younes Belkada's blog"><meta property="og:title" content="An approach for fitness exercise scoring using Deep Learning"><meta property="og:description" content="Introduction Imagine a world where (almost) everything is powered by Artificial Intelligence. Today, some signs of an Artifical Intelligence-guided society are coming into existence. Autonomous cars can automately drive you from a point A to a point B, and more recently, Tesla has revealed the Tesla Bot, the humanoid robot that will be able to help humans for simple tasks.
Elon Musk when revealing the Tesla Bot - August 2021 -Source: autoplus."><meta property="og:type" content="article"><meta property="og:url" content="http://example.org/projects/pose-socring/"><meta property="og:image" content="http://example.org/logo.png"><meta property="article:section" content="projects"><meta property="article:published_time" content="2020-05-24T20:26:19+02:00"><meta property="article:modified_time" content="2020-05-24T20:26:19+02:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://example.org/logo.png"><meta name=twitter:title content="An approach for fitness exercise scoring using Deep Learning"><meta name=twitter:description content="Introduction Imagine a world where (almost) everything is powered by Artificial Intelligence. Today, some signs of an Artifical Intelligence-guided society are coming into existence. Autonomous cars can automately drive you from a point A to a point B, and more recently, Tesla has revealed the Tesla Bot, the humanoid robot that will be able to help humans for simple tasks.
Elon Musk when revealing the Tesla Bot - August 2021 -Source: autoplus."><meta name=application-name content="Younes Belkada"><meta name=apple-mobile-web-app-title content="Younes Belkada"><meta name=theme-color content="#ffc40d"><meta name=msapplication-TileColor content="#da532c"><link rel=icon href=favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=http://example.org/projects/pose-socring/><link rel=prev href=http://example.org/projects/table-structure/><link rel=next href=http://example.org/projects/looking/><link rel=stylesheet href=/css/page.min.css><link rel=stylesheet href=/css/home.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"An approach for fitness exercise scoring using Deep Learning","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"http:\/\/example.org\/projects\/pose-socring\/"},"genre":"projects","keywords":"Human Pose, Deep Learning, Fitness Exercises","wordcount":836,"url":"http:\/\/example.org\/projects\/pose-socring\/","datePublished":"2020-05-24T20:26:19+02:00","dateModified":"2020-05-24T20:26:19+02:00","publisher":{"@type":"Organization","name":"Younes Belkada"},"author":{"@type":"Person","name":"Younes Belkada"},"description":""}</script></head><body data-header-desktop data-header-mobile><script>(window.localStorage&&localStorage.getItem('theme')?localStorage.getItem('theme')==='dark':'auto'==='auto'?window.matchMedia('(prefers-color-scheme: dark)').matches:'auto'==='dark')&&document.body.setAttribute('theme','dark')</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="Younes Belkada's blog">Younes Belkada's blog</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/about/>About </a><a class=menu-item href=/projects/>Projects </a><a class=menu-item href=/notes/>Notes </a><a class=menu-item href=/posts/>Posts </a><a class=menu-item href=/tags/>Tags </a><a class=menu-item href=/categories/>Categories </a><span class="menu-item delimiter"></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw"></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="Younes Belkada's blog">Younes Belkada's blog</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><a class=menu-item href=/about/ title>About</a><a class=menu-item href=/projects/ title>Projects</a><a class=menu-item href=/notes/ title>Notes</a><a class=menu-item href=/posts/ title>Posts</a><a class=menu-item href=/tags/ title>Tags</a><a class=menu-item href=/categories/ title>Categories</a><div class=menu-item><a href=javascript:void(0); class=theme-switch title="Switch Theme"><i class="fas fa-adjust fa-fw"></i></a></div></div></div></header><main class=main><div class=container><div class=toc id=toc-auto style=top:8rem><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single special" data-toc=enable><h2 class="single-title animated fadeInDown faster">An approach for fitness exercise scoring using Deep Learning</h2><div class=single-card><div class="details toc" id=toc-static data-kept=true><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><ul><li><a href=#fitness-exercises-and-ai>Fitness exercises and AI?</a></li></ul></li></ul><ul><li><ul><li><a href=#what-is-going-to-be-the-input-data>What is going to be the input data?</a></li><li><a href=#transforming-the-input-into-another-space>Transforming the input into another space</a></li><li><a href=#deal-with-different-numbers-of-frames>Deal with different numbers of frames</a></li></ul></li></ul><ul><li><ul><li><a href=#score-predictor-as-a-1d-cnn>Score predictor as a 1D-CNN</a></li><li><a href=#score-predictor-as-a-simple-lstm-model>Score predictor as a simple LSTM model</a></li></ul></li></ul></nav></div></div><div class=content id=content><h1 id=introduction>Introduction</h1><p>Imagine a world where (almost) everything is powered by Artificial Intelligence. Today, some signs of an Artifical Intelligence-guided society are coming into existence. Autonomous cars can automately drive you from a point A to a point B, and more recently, Tesla has revealed the <em><strong>Tesla Bot</strong></em>, <a href=https://usa.inquirer.net/81836/tesla-bot-everything-you-need-to-know target=_blank rel="noopener noreffer">the humanoid robot</a> that will be able to help humans for simple tasks.</p><figure><a class=lightgallery href=/images/projects/Tesla_Bot.png title="Source: autoplus.fr" data-thumbnail=/images/projects/Tesla_Bot.png data-sub-html="<h2>Elon Musk when revealing the Tesla Bot - August 2021 -</h2><p>Source: autoplus.fr</p>"><img class=lazyload src=/svg/loading.min.svg data-src=/images/projects/Tesla_Bot.png data-srcset="/images/projects/Tesla_Bot.png, /images/projects/Tesla_Bot.png 1.5x, /images/projects/Tesla_Bot.png 2x" data-sizes=auto alt=/images/projects/Tesla_Bot.png height=600 width=600></a><figcaption class=image-caption>Elon Musk when revealing the Tesla Bot - August 2021 -</figcaption></figure><p>Apart from having society full of AI-powered robots, back in 2019 when we have starting the project together with my teammates and the laboratory <a href=https://www.isir.upmc.fr/ target=_blank rel="noopener noreffer">ISIR</a> from Sobonne University, we just wanted to <em><strong>try</strong></em> to tackle to problematic of having an AI-based gym trainer for fitness exercises.</p><h3 id=fitness-exercises-and-ai>Fitness exercises and AI?</h3><p>Fitness exercises consists mostly of repeated movements that needs to be executed in the most accurate way possible to solicit some specific joints and muscles of our body. If an AI <em><strong>learns</strong></em> how a specific exercise needs to be done correclty, given an execution of this exercise the AI should be able to interpret how far this execution it is from the learned execution. The problem seems exetremly straightforward to forumulate but very hard to translate it into a Machine Learning problem.</p><h1 id=challenges>Challenges</h1><h3 id=what-is-going-to-be-the-input-data>What is going to be the input data?</h3><p>If deployed into a real-world application, the input data would clearly be a video. As stated in the previous section, the AI needs to learn how to perform a right execution, which consists of a video of a movement.
Does the AI needs to be end-to-end? (<em><strong>Directly from the video to the score</strong></em>). <em>Not that easy</em>.</p><p>Given the lack (or the inexistence) of a labeled data for this task, the problematic became very challenging but exciting. We had to create a custom dataset by involving staff members from the lab and hard work since we had to label each frame from each video.</p><p>The project&rsquo;s main problematic has rapidly became <em><strong>Can we create an AI that classifies and scores a fitness movement?</strong></em> to <em><strong>Is Deep Learning well adapted to score a movement?</strong></em></p><h3 id=transforming-the-input-into-another-space>Transforming the input into another space</h3><p>Having a model that learns everything end-to-end directly from the video is extremely computationnaly expensive and <strong>not robust in practice</strong>. It can easily overfit into the persons we have used to train the model or overfit to some contextual information we do not have control on (e.g. the background, the lighting of the room in the videos, etc.). Thus, the input data absolulety needs to be transformed in order to make them more understandable for the Deep Learning model to process it, and to avoid our common ennemy: <em>overfitting</em>.</p><p><strong>Long live human poses!</strong> What if we express each frame into only the joints of the person in the video? By doing this, we drastically reduce the amount of data (each frame can be expressed using only 30 data points instead of 3x256 pixels!). Back in 2019, <a href=https://github.com/CMU-Perceptual-Computing-Lab/openpose target=_blank rel="noopener noreffer">OpenPose</a> was the state-of-the-art method for 2D human pose estimation model.</p><figure><a class=lightgallery href=/images/projects/pose_face_hands.gif title="Source: OpenPose's official repository" data-thumbnail=/images/projects/pose_face_hands.gif data-sub-html="<h2>Qualitative results from OpenPose</h2><p>Source: OpenPose's official repository</p>"><img class=lazyload src=/svg/loading.min.svg data-src=/images/projects/pose_face_hands.gif data-srcset="/images/projects/pose_face_hands.gif, /images/projects/pose_face_hands.gif 1.5x, /images/projects/pose_face_hands.gif 2x" data-sizes=auto alt=/images/projects/pose_face_hands.gif height=400 width=500></a><figcaption class=image-caption>Qualitative results from OpenPose</figcaption></figure><p>This approach to tackle the problem seemed perfect to us. OpenPose was state-of-the-art, time-consistent (consistent results between each frame) and extremly robust since it has been trained on a very large dataset with a wide variety of different people, background images, lighting conditions, etc. In addition, the outputed keypoints can be normalized and the score would be independent to the size of the human, which in practice is the case.</p><h3 id=deal-with-different-numbers-of-frames>Deal with different numbers of frames</h3><p>Each frame is now expressed into a vector of size 30. A video is a concatenation of frames, thus can be expressed with a concatenation of generated vectors. How to deal with inconsitent number of frames accross each video? By just applying a fixed zero-padding on those tensors. Let&rsquo;s assume the maximum number of frames accross all videos is <em>N</em>. Then each video would have a size <em>(30xN)</em> and the irregular videos will be zero-padded.</p><h1 id=implementations>Implementations</h1><p>After manually labelling the data and transforming each video into a <em>(30xN)</em> dimensional tensor we have tried several approaches to output a score given the tensors.</p><p>Each <em>30-dimensional</em> vector is concatenated in the horizontal direction. Arranging the data like the following is similar to having a sequential data where each column corresponds to a specific timestep.</p><h3 id=score-predictor-as-a-1d-cnn>Score predictor as a 1D-CNN</h3><p>The 1-dimensional filter can learn the linear correlation between each joint at each time step.</p><figure><a class=lightgallery href=/images/projects/conv_1D_time.gif title="Source: cezannec.github.io/" data-thumbnail=/images/projects/conv_1D_time.gif data-sub-html="<h2>Overview of a 1D-CNN applied to text data</h2><p>Source: cezannec.github.io/</p>"><img class=lazyload src=/svg/loading.min.svg data-src=/images/projects/conv_1D_time.gif data-srcset="/images/projects/conv_1D_time.gif, /images/projects/conv_1D_time.gif 1.5x, /images/projects/conv_1D_time.gif 2x" data-sizes=auto alt=/images/projects/conv_1D_time.gif height=500 width=500></a><figcaption class=image-caption>Overview of a 1D-CNN applied to text data</figcaption></figure><h3 id=score-predictor-as-a-simple-lstm-model>Score predictor as a simple LSTM model</h3><p>It is a common practice in the Deep Learning litterature to use a LSTM model when dealing with sequential data.</p><figure><a class=lightgallery href=/images/projects/lstm.gif title=/images/projects/lstm.gif data-thumbnail=/images/projects/lstm.gif data-sub-html="<h2>Overview of a LSTM model</h2>"><img class=lazyload src=/svg/loading.min.svg data-src=/images/projects/lstm.gif data-srcset="/images/projects/lstm.gif, /images/projects/lstm.gif 1.5x, /images/projects/lstm.gif 2x" data-sizes=auto alt=/images/projects/lstm.gif height=500 width=500></a><figcaption class=image-caption>Overview of a LSTM model</figcaption></figure><h1 id=conclusion>Conclusion</h1><ul><li>Trying to have an end-to-end AI is extremely difficult if we want to deploy a robust AI. Breaking down the problem into smaller problems can help and must be considerd.</li></ul></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-tag><span><a href=/tags/human-pose/>Human Pose</a>
</span><span><a href=/tags/deep-learning/>Deep Learning</a>
</span><span><a href=/tags/fitness-exercises/>Fitness Exercises</a></span></div><div class=post-info-line><div class=post-info-mod><span>Updated on 2020-05-24</span></div><div class=post-info-mod></div></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on Linkedin" data-sharer=linkedin data-url=http://example.org/projects/pose-socring/><i class="fab fa-linkedin fa-fw"></i></a><a href=javascript:void(0); title="Share on WhatsApp" data-sharer=whatsapp data-url=http://example.org/projects/pose-socring/ data-title="An approach for fitness exercise scoring using Deep Learning" data-web><i class="fab fa-whatsapp fa-fw"></i></a></span></div></div><div class=post-nav><a href=/projects/table-structure/ class=prev rel=prev title="An unsupervised method for table structure recognition"><i class="fas fa-angle-left fa-fw"></i>Previous Post</a>
<a href=/projects/looking/ class=next rel=next title="In-the-wild eye contact detection for Autonomous Vehicles">Next Post<i class="fas fa-angle-right fa-fw"></i></a></div></div></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line>Powered by <a href=https://gohugo.io/ target=_blank rel="noopener noreffer" title="Hugo 0.85.0">Hugo</a> | Theme - <a href=https://github.com/khusika/FeelIt target=_blank rel="noopener noreffer" title="FeelIt 1.0.1"><i class="fas fa-hand-holding-heart fa-fw"></i> FeelIt</a></div><div class=footer-line itemscope itemtype=http://schema.org/CreativeWork><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2021</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/>Younes Belkada</a></span></div><a title="Real Time Web Analytics" href=http://clicky.com/101337009><img alt=Clicky src=//static.getclicky.com/media/links/badge.gif border=0></a>
<script async src=//static.getclicky.com/101337009.js></script><noscript><p><img alt=Clicky width=1 height=1 src=//in.getclicky.com/101337009ns.gif></p></noscript></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-chevron-up fa-fw"></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment-alt fa-fw"></i></a></div><link rel=stylesheet href=/lib/fontawesome-free/all.min.css><link rel=stylesheet href=/lib/animate/animate.min.css><link rel=stylesheet href=/lib/lightgallery/lightgallery.min.css><link rel=stylesheet href=/lib/katex/katex.min.css><link rel=stylesheet href=/lib/katex/copy-tex.min.css><script src=/lib/lazysizes/lazysizes.min.js></script><script src=/lib/lightgallery/lightgallery.min.js></script><script src=/lib/lightgallery/lg-thumbnail.min.js></script><script src=/lib/lightgallery/lg-zoom.min.js></script><script src=/lib/clipboard/clipboard.min.js></script><script src=/lib/sharer/sharer.min.js></script><script src=/lib/katex/katex.min.js></script><script src=/lib/katex/auto-render.min.js></script><script src=/lib/katex/copy-tex.min.js></script><script src=/lib/katex/mhchem.min.js></script><script>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:10},comment:{},lightGallery:{actualSize:!1,exThumbImage:"data-thumbnail",hideBarsDelay:2e3,selector:".lightgallery",speed:400,thumbContHeight:80,thumbWidth:80,thumbnail:!0},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1}}</script><script src=/js/theme.min.js></script></body></html>